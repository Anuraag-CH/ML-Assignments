{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_DONORS_model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0xeeHcDnBEU",
        "colab_type": "code",
        "outputId": "7bb00f90-f593-4e0b-ce9a-17ba6c3a0f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ./drive/My Drive/LSTM"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/LSTM\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: './drive/My Drive/LSTM'\n",
            "/content/drive/My Drive/LSTM\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTR3SqLunSZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "a738e2d7-2a42-4634-cfff-519fddf483ae"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input , Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import concatenate\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.models import Model\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "import pickle\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "from chart_studio import plotly\n",
        "import plotly.offline as offline\n",
        "from keras.layers import LSTM\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau, EarlyStopping\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import seaborn as sns\n",
        "from keras.regularizers import l2\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.models import load_model\n",
        "from IPython.display import Image\n",
        "from scipy.sparse import hstack\n",
        "from keras.layers import Conv1D\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from prettytable import PrettyTable"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQRJIEgAq7Fs",
        "colab_type": "code",
        "outputId": "336f8328-97d5-4791-f8a0-7edba7091f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        }
      },
      "source": [
        "X = pd.read_csv('preprocessed_data.csv')\n",
        "X=X[0:100000]\n",
        "print(X.columns)\n",
        "X.head(2)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
            "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
            "       'clean_categories', 'clean_subcategories', 'essay', 'price'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>project_is_approved</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_prek_2</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "      <td>math_science</td>\n",
              "      <td>appliedsciences health_lifescience</td>\n",
              "      <td>i fortunate enough use fairy tale stem kits cl...</td>\n",
              "      <td>725.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ut</td>\n",
              "      <td>ms</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>specialneeds</td>\n",
              "      <td>imagine 8 9 years old you third grade classroo...</td>\n",
              "      <td>213.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  school_state  ...   price\n",
              "0           ca  ...  725.05\n",
              "1           ut  ...  213.03\n",
              "\n",
              "[2 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSbs69mKtWV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y=X['project_is_approved']\n",
        "X=X.drop(['project_is_approved'],axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrpDu64_czAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,stratify=Y)\n",
        "x_train,x_cv,y_train,y_cv=train_test_split(x_train,y_train,test_size=0.25,stratify=y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp323gFoj38X",
        "colab_type": "code",
        "outputId": "319e9428-62d8-4572-ae56-bdd0d873665a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "x_train.head(2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>school_state</th>\n",
              "      <th>teacher_prefix</th>\n",
              "      <th>project_grade_category</th>\n",
              "      <th>teacher_number_of_previously_posted_projects</th>\n",
              "      <th>clean_categories</th>\n",
              "      <th>clean_subcategories</th>\n",
              "      <th>essay</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63801</th>\n",
              "      <td>il</td>\n",
              "      <td>mrs</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>0</td>\n",
              "      <td>literacy_language</td>\n",
              "      <td>literacy</td>\n",
              "      <td>reading gives us place go stay my 5th grade st...</td>\n",
              "      <td>143.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84145</th>\n",
              "      <td>nj</td>\n",
              "      <td>ms</td>\n",
              "      <td>grades_3_5</td>\n",
              "      <td>1</td>\n",
              "      <td>literacy_language</td>\n",
              "      <td>literacy</td>\n",
              "      <td>as teacher low income high poverty school dist...</td>\n",
              "      <td>126.66</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      school_state  ...   price\n",
              "63801           il  ...  143.91\n",
              "84145           nj  ...  126.66\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IEZvZ71kNLq",
        "colab_type": "code",
        "outputId": "fddb51ab-e20b-46a4-e317-1dc3fd37ee84",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_cv.shape, y_cv.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 8) (60000,)\n",
            "(20000, 8) (20000,)\n",
            "(20000, 8) (20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmXRHlSlkQGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://stackoverflow.com/questions/21057621/sklearn-labelencoder-with-never-seen-before-values\n",
        "\n",
        "class LabelEncoderExt(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        It differs from LabelEncoder by handling new classes and providing a value for it [Unknown]\n",
        "        Unknown will be added in fit and transform will take care of new item. It gives unknown class id\n",
        "        \"\"\"\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        # self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "    def fit(self, data_list):\n",
        "        \"\"\"\n",
        "        This will fit the encoder for all the unique values and introduce unknown value\n",
        "        :param data_list: A list of string\n",
        "        :return: self\n",
        "        \"\"\"\n",
        "        self.label_encoder = self.label_encoder.fit(list(data_list) + ['Unknown'])\n",
        "        self.classes_ = self.label_encoder.classes_\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, data_list):\n",
        "        \"\"\"\n",
        "        This will transform the data_list to id list where the new values get assigned to Unknown class\n",
        "        :param data_list:\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        new_data_list = list(data_list)\n",
        "        for unique_item in np.unique(data_list):\n",
        "            if unique_item not in self.label_encoder.classes_:\n",
        "                new_data_list = ['Unknown' if x==unique_item else x for x in new_data_list]\n",
        "\n",
        "        return self.label_encoder.transform(new_data_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYRYq16nsCfv",
        "colab_type": "code",
        "outputId": "ae228df1-5995-4c1e-c4ff-0ae5c5e514c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "x_train.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['school_state', 'teacher_prefix', 'project_grade_category',\n",
              "       'teacher_number_of_previously_posted_projects', 'clean_categories',\n",
              "       'clean_subcategories', 'essay', 'price'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxWAWS0smG9M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = LabelEncoderExt()\n",
        "label_encoder.fit(x_train['teacher_prefix'].values)\n",
        "x_train_teacher_ohe=label_encoder.transform(x_train['teacher_prefix'].values)\n",
        "x_cv_teacher_ohe=label_encoder.transform(x_cv['teacher_prefix'].values)\n",
        "x_test_teacher_ohe=label_encoder.transform(x_test['teacher_prefix'].values)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoderExt()\n",
        "label_encoder.fit(x_train['school_state'].values)\n",
        "x_train_school_ohe=label_encoder.transform(x_train['school_state'].values)\n",
        "x_cv_school_ohe=label_encoder.transform(x_cv['school_state'].values)\n",
        "x_test_school_ohe=label_encoder.transform(x_test['school_state'].values)\n",
        "\n",
        "label_encoder = LabelEncoderExt()\n",
        "label_encoder.fit(x_train['school_state'].values)\n",
        "x_train_project_ohe=label_encoder.transform(x_train['project_grade_category'].values)\n",
        "x_cv_project_ohe=label_encoder.transform(x_cv['project_grade_category'].values)\n",
        "x_test_project_ohe=label_encoder.transform(x_test['project_grade_category'].values)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoderExt()\n",
        "label_encoder.fit(x_train['school_state'].values)\n",
        "x_train_clean_cat_ohe=label_encoder.transform(x_train['clean_categories'].values)\n",
        "x_cv_clean_cat_ohe=label_encoder.transform(x_cv['clean_categories'].values)\n",
        "x_test_clean_cat_ohe=label_encoder.transform(x_test['clean_categories'].values)\n",
        "\n",
        "label_encoder = LabelEncoderExt()\n",
        "label_encoder.fit(x_train['school_state'].values)\n",
        "x_train_clean_subcat_ohe=label_encoder.transform(x_train['clean_subcategories'].values)\n",
        "x_cv_clean_subcat_ohe=label_encoder.transform(x_cv['clean_subcategories'].values)\n",
        "x_test_clean_subcat_ohe=label_encoder.transform(x_test['clean_subcategories'].values)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRHyh9ok_9Pf",
        "colab_type": "code",
        "outputId": "ef899b36-2db6-4eb6-81b4-92a8c828c326",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "normalizer = Normalizer()\n",
        "# normalizer.fit(X_train['price'].values)\n",
        "# this will rise an error Expected 2D array, got 1D array instead: \n",
        "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
        "# Reshape your data either using \n",
        "# array.reshape(-1, 1) if your data has a single feature \n",
        "# array.reshape(1, -1)  if it contains a single sample.\n",
        "normalizer.fit(x_train['teacher_number_of_previously_posted_projects'].values.reshape(1,-1))\n",
        "\n",
        "x_train_teacher_no = normalizer.transform(x_train['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "x_cv_teacher_no = normalizer.transform(x_cv['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "x_test_teacher_no = normalizer.transform(x_test['teacher_number_of_previously_posted_projects'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(x_train_teacher_no.shape, y_train.shape)\n",
        "print(x_cv_teacher_no.shape, y_cv.shape)\n",
        "print(x_test_teacher_no.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(60000, 1) (60000,)\n",
            "(20000, 1) (20000,)\n",
            "(20000, 1) (20000,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV9Pp94xAVuu",
        "colab_type": "code",
        "outputId": "da09a8c4-9eef-4885-a0db-dc9245ca64b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "normalizer = Normalizer()\n",
        "# normalizer.fit(X_train['price'].values)\n",
        "# this will rise an error Expected 2D array, got 1D array instead: \n",
        "# array=[105.22 215.96  96.01 ... 368.98  80.53 709.67].\n",
        "# Reshape your data either using \n",
        "# array.reshape(-1, 1) if your data has a single feature \n",
        "# array.reshape(1, -1)  if it contains a single sample.\n",
        "normalizer.fit(x_train['price'].values.reshape(1,-1))\n",
        "\n",
        "x_train_price_norm = normalizer.transform(x_train['price'].values.reshape(-1,1))\n",
        "x_cv_price_norm = normalizer.transform(x_cv['price'].values.reshape(-1,1))\n",
        "x_test_price_norm = normalizer.transform(x_test['price'].values.reshape(-1,1))\n",
        "\n",
        "print(\"After vectorizations\")\n",
        "print(x_train_price_norm.shape, y_train.shape)\n",
        "print(x_cv_price_norm.shape, y_cv.shape)\n",
        "print(x_test_price_norm.shape, y_test.shape)\n",
        "print(\"=\"*100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After vectorizations\n",
            "(60000, 1) (60000,)\n",
            "(20000, 1) (20000,)\n",
            "(20000, 1) (20000,)\n",
            "====================================================================================================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3HDJlx6Cq-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remaining_train = np.hstack((x_train_price_norm,x_train_teacher_no))\n",
        "remaining_cv = np.hstack((x_cv_price_norm,x_cv_teacher_no))\n",
        "remaining_test = np.hstack((x_test_price_norm,x_test_teacher_no))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QiOg66wnoDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length=300\n",
        "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
        "def padded(encoded_docs):  \n",
        "  max_length = 300\n",
        "  padded_docs = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "  return padded_docs\n",
        "#https://stackoverflow.com/posts/51956230/revisions\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train.essay)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "# integer encode the documents\n",
        "encoded_docs = t.texts_to_sequences(x_train.essay)\n",
        "essay_padded_train = padded(encoded_docs)\n",
        "encoded_docs = t.texts_to_sequences(x_cv.essay)\n",
        "essay_padded_cv = padded(encoded_docs)\n",
        "encoded_docs = t.texts_to_sequences(x_test.essay)\n",
        "essay_padded_test = padded(encoded_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1vL2y2lnn4u",
        "colab_type": "code",
        "outputId": "d3f2d6fa-99c8-474e-e0e0-232b94296628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with open('glove_vectors', 'rb') as f:\n",
        "    model = pickle.load(f)\n",
        "    glove_words =  set(model.keys())\n",
        "    \n",
        "# for train\n",
        "embedding_matrix= np.zeros((vocab_size, 300))\n",
        "for word, i in t.word_index.items():\n",
        "    if word in glove_words:\n",
        "        embedding_vector = model[word]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "print(\"embedding matrix shape\",embedding_matrix.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "embedding matrix shape (44576, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TN8_1y5JcKKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=2)\n",
        "y_cv = to_categorical(y_cv, num_classes=2)\n",
        "y_test = to_categorical(y_test, num_classes=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSMat26bnny9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorboardcolab import *\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import LeakyReLU\n",
        "import keras.backend as K\n",
        "#K.clear_session()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsGifTBjr8J8",
        "colab_type": "code",
        "outputId": "e5cb9236-b9cf-4311-d252-d1b4bac3e9cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# https://github.com/ravi-1654003/LSTM-DonorsChoose/blob/master/LSTM_DonorsChoose.ipynb\n",
        "essay_input = Input(shape=(300,), name='essay_input')\n",
        "\n",
        "x = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=300)(essay_input)\n",
        "lstm_out = LSTM(100,recurrent_dropout=0.5,return_sequences=True)(x)\n",
        "flatten_1 = Flatten()(lstm_out)\n",
        "\n",
        "state = Input(shape=(1,), name='school_state')\n",
        "x = Embedding(52, 10, input_length=1)(state)\n",
        "flatten_2 = Flatten()(x)\n",
        "\n",
        "\n",
        "project_grade_category = Input(shape=(1,), name='project_grade_category')\n",
        "x = Embedding(5, 10, input_length=1)(project_grade_category)\n",
        "flatten_3 = Flatten()(x)\n",
        "\n",
        "\n",
        "clean_categories = Input(shape=(1,), name='clean_categories')\n",
        "x = Embedding(51, 10, input_length=1)(clean_categories)\n",
        "flatten_4 = Flatten()(x)\n",
        "\n",
        "\n",
        "clean_sub_categories = Input(shape=(1,), name='clean_sub_categories')\n",
        "x = Embedding(393, 10, input_length=1)(clean_sub_categories)\n",
        "flatten_5 = Flatten()(x)\n",
        "\n",
        "\n",
        "teacher_prefix = Input(shape=(1,), name='teacher_prefix')\n",
        "x = Embedding(6, 10, input_length=1)(teacher_prefix)\n",
        "flatten_6 = Flatten()(x)\n",
        "\n",
        "\n",
        "remaining_input = Input(shape=(2,), name='remaining_input')\n",
        "dense_1 = Dense(1, activation='relu',kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.001))(remaining_input)\n",
        "\n",
        "\n",
        "\n",
        "x = concatenate([flatten_1,flatten_2,flatten_3,flatten_4,flatten_5,flatten_6,dense_1])\n",
        "\n",
        "x = Dense(256, activation='relu',kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(.5)(x)\n",
        "x = Dense(128, activation='relu',kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.001))(x)\n",
        "x = Dropout(.5)(x)\n",
        "\n",
        "x = Dense(64, activation='relu',kernel_initializer=\"he_normal\",kernel_regularizer=l2(0.001))(x)\n",
        "final_output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=[essay_input,state,project_grade_category,clean_categories,clean_sub_categories,teacher_prefix,remaining_input], outputs=[final_output])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "essay_input (InputLayer)        (None, 300)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_13 (Embedding)        (None, 300, 300)     13372800    essay_input[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "school_state (InputLayer)       (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "project_grade_category (InputLa (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "clean_categories (InputLayer)   (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "clean_sub_categories (InputLaye (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "teacher_prefix (InputLayer)     (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 300, 100)     160400      embedding_13[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_14 (Embedding)        (None, 1, 10)        520         school_state[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "embedding_15 (Embedding)        (None, 1, 10)        50          project_grade_category[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_16 (Embedding)        (None, 1, 10)        510         clean_categories[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "embedding_17 (Embedding)        (None, 1, 10)        3930        clean_sub_categories[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 1, 10)        60          teacher_prefix[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "remaining_input (InputLayer)    (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_13 (Flatten)            (None, 30000)        0           lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_14 (Flatten)            (None, 10)           0           embedding_14[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 10)           0           embedding_15[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_16 (Flatten)            (None, 10)           0           embedding_16[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_17 (Flatten)            (None, 10)           0           embedding_17[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "flatten_18 (Flatten)            (None, 10)           0           embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1)            3           remaining_input[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 30051)        0           flatten_13[0][0]                 \n",
            "                                                                 flatten_14[0][0]                 \n",
            "                                                                 flatten_15[0][0]                 \n",
            "                                                                 flatten_16[0][0]                 \n",
            "                                                                 flatten_17[0][0]                 \n",
            "                                                                 flatten_18[0][0]                 \n",
            "                                                                 dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 256)          7693312     concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 256)          0           dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 128)          32896       dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_6 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 64)           8256        dropout_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 2)            130         dense_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 21,272,867\n",
            "Trainable params: 21,272,867\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbd2qBOWt6O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#https://github.com/ravi-1654003/LSTM-DonorsChoose/blob/master/LSTM_DonorsChoose.ipynb\n",
        "checkpoint_1 = ModelCheckpoint(\"model_1.h5\",\n",
        "                             monitor=\"val_auroc\",\n",
        "                             mode=\"max\",\n",
        "                             save_best_only = True,\n",
        "                             verbose=1)\n",
        "earlystop_1 = EarlyStopping(monitor = 'val_auroc', \n",
        "                            mode=\"max\",\n",
        "                            min_delta = 0, \n",
        "                            patience = 2,\n",
        "                            verbose = 1)\n",
        "\n",
        "tensorboard_1 = TensorBoard(log_dir='graph_model_1', batch_size=512)\n",
        "\n",
        "callbacks_1 = [checkpoint_1,earlystop_1,tensorboard_1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXuO8PWDt6M9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#auc\n",
        "def auroc(y_true, y_pred):\n",
        "    return tf.py_func(roc_auc_score, (y_true, y_pred), tf.double)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2SQ8u2W0l2UN",
        "colab": {}
      },
      "source": [
        "train = [essay_padded_train,x_train_school_ohe,x_train_project_ohe,x_train_clean_cat_ohe,x_train_clean_subcat_ohe,x_train_teacher_ohe,remaining_train]\n",
        "cv=[essay_padded_cv,x_cv_school_ohe,x_cv_project_ohe,x_cv_clean_cat_ohe,x_cv_clean_subcat_ohe,x_cv_teacher_ohe,remaining_cv]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKh9WRAMKtni",
        "colab_type": "code",
        "outputId": "e7ddde10-b989-4c75-d802-c099d5afd070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "import keras\n",
        "#from keras.optimizers import Adam\n",
        "#optim=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "from keras.optimizers import Adadelta\n",
        "optim=keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=1e-08, decay=0.0)\n",
        "#from keras.optimizers import Adagrad\n",
        "#optim = keras.optimizers.Adagrad(lr=0.01, epsilon=1e-08, decay=0.0)\n",
        "model.compile(optimizer=optim, loss='categorical_crossentropy', metrics=[auroc])\n",
        "history_1 = model.fit(train, y_train, batch_size=256, epochs=10, verbose=1,callbacks=callbacks_1, validation_data=(cv, y_cv))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 20000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 1.6694 - auroc: 0.5408 - val_loss: 0.5349 - val_auroc: 0.7000\n",
            "\n",
            "Epoch 00001: val_auroc improved from -inf to 0.70001, saving model to model_1.h5\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.4976 - auroc: 0.7193 - val_loss: 0.5049 - val_auroc: 0.7417\n",
            "\n",
            "Epoch 00002: val_auroc improved from 0.70001 to 0.74172, saving model to model_1.h5\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.4504 - auroc: 0.7807 - val_loss: 0.5006 - val_auroc: 0.7430\n",
            "\n",
            "Epoch 00003: val_auroc improved from 0.74172 to 0.74296, saving model to model_1.h5\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 125s 2ms/step - loss: 0.4252 - auroc: 0.8140 - val_loss: 0.4606 - val_auroc: 0.7380\n",
            "\n",
            "Epoch 00004: val_auroc did not improve from 0.74296\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 124s 2ms/step - loss: 0.4000 - auroc: 0.8491 - val_loss: 0.4773 - val_auroc: 0.7333\n",
            "\n",
            "Epoch 00005: val_auroc did not improve from 0.74296\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhboQZlbiDGz",
        "colab_type": "code",
        "outputId": "bde47e19-8514-446d-a0ea-c2c02bbb114c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test=[essay_padded_test,x_test_school_ohe,x_test_project_ohe,x_test_clean_cat_ohe,x_test_clean_subcat_ohe,x_test_teacher_ohe,remaining_test]\n",
        "y_pred=model.predict(test)\n",
        "a=roc_auc_score(y_test,y_pred)\n",
        "print(\"Test auc score\",a)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test auc score 0.7367849617340079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jTOajr1tfQp",
        "colab_type": "code",
        "outputId": "accf9de7-72ad-4144-a4e2-0a4a72666a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUtIl_lBhM0S",
        "colab_type": "code",
        "outputId": "2ebdd8c6-6b91-4f98-e447-bc224f369606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorboard --logdir graph_model_1"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 499), started 1:13:12 ago. (Use '!kill 499' to kill it.)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}