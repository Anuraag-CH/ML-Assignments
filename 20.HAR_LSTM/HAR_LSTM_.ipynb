{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAR_LSTM_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypuVHpngOWHa",
        "colab_type": "code",
        "outputId": "80d8fc06-f343-4559-d395-e25565a2c70d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd ./drive/My Drive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JAjLS8AOho2",
        "colab_type": "code",
        "outputId": "66fa7469-385b-4a78-9d7b-4bebee0c0181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "# Importing tensorflow\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.set_random_seed(42)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV33Cs1POiSX",
        "colab_type": "code",
        "outputId": "9f0e02cc-d00b-42a7-e5ed-adae919dca21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Importing libraries\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM\n",
        "from keras.layers.core import Dense, Dropout"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRkIUf8hOxxm",
        "colab_type": "text"
      },
      "source": [
        "#Binary Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9dsdCkSOvy-",
        "colab_type": "code",
        "outputId": "109762f7-b6df-4b65-c663-1e4a7112a2b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'\n",
        "\n",
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]\n",
        "\n",
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = 'UCI_HAR_Dataset/'+subset+'/Inertial Signals/'+signal+'_'+subset+'.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))\n",
        "\n",
        "    \n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = 'UCI_HAR_Dataset/'+subset+'/y_'+subset+'.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "    y[y<=3] = 0\n",
        "    y[y>3] = 1\n",
        "\n",
        "    return pd.get_dummies(y).as_matrix()\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_52dj1xOqs_",
        "colab_type": "code",
        "outputId": "71890c05-fd1d-4754-820c-43a0e4840fec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "timesteps = len(X_train[0])\n",
        "input_dim = len(X_train[0][0])\n",
        "\n",
        "print(timesteps)\n",
        "print(input_dim)\n",
        "print(len(X_train))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "128\n",
            "9\n",
            "7352\n",
            "(7352, 128, 9)\n",
            "(7352, 2)\n",
            "(2947, 128, 9)\n",
            "(2947, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEGQIN99PEnP",
        "colab_type": "code",
        "outputId": "7b286d09-fdb4-426e-fee9-ca548417fbf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Training with the best parameters\n",
        "\n",
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(32, input_shape=(timesteps, input_dim)))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train,\n",
        "          Y_train,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_test, Y_test),\n",
        "          epochs=15)\n",
        "\n",
        "# Confusion Matrix\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "score"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 32)                5376      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 66        \n",
            "=================================================================\n",
            "Total params: 5,442\n",
            "Trainable params: 5,442\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 7352 samples, validate on 2947 samples\n",
            "Epoch 1/15\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.3277 - acc: 0.8731 - val_loss: 0.1111 - val_acc: 0.9650\n",
            "Epoch 2/15\n",
            "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0671 - acc: 0.9830 - val_loss: 0.0557 - val_acc: 0.9841\n",
            "Epoch 3/15\n",
            "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0349 - acc: 0.9940 - val_loss: 0.0595 - val_acc: 0.9854\n",
            "Epoch 4/15\n",
            "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0290 - acc: 0.9965 - val_loss: 0.0675 - val_acc: 0.9854\n",
            "Epoch 5/15\n",
            "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0176 - acc: 0.9978 - val_loss: 0.0465 - val_acc: 0.9932\n",
            "Epoch 6/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0212 - acc: 0.9974 - val_loss: 0.0226 - val_acc: 0.9891\n",
            "Epoch 7/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0214 - acc: 0.9969 - val_loss: 0.1314 - val_acc: 0.9773\n",
            "Epoch 8/15\n",
            "7352/7352 [==============================] - 20s 3ms/step - loss: 0.0079 - acc: 0.9986 - val_loss: 0.0146 - val_acc: 0.9983\n",
            "Epoch 9/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0073 - acc: 0.9992 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 10/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0089 - acc: 0.9990 - val_loss: 0.0109 - val_acc: 0.9922\n",
            "Epoch 11/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0057 - acc: 0.9993 - val_loss: 0.0179 - val_acc: 0.9908\n",
            "Epoch 12/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0133 - val_acc: 0.9912\n",
            "Epoch 13/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0054 - acc: 0.9993 - val_loss: 0.0679 - val_acc: 0.9881\n",
            "Epoch 14/15\n",
            "7352/7352 [==============================] - 21s 3ms/step - loss: 0.0373 - acc: 0.9973 - val_loss: 0.2038 - val_acc: 0.9786\n",
            "Epoch 15/15\n",
            "7352/7352 [==============================] - 22s 3ms/step - loss: 0.0257 - acc: 0.9978 - val_loss: 0.0312 - val_acc: 0.9888\n",
            "2947/2947 [==============================] - 1s 359us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03120530384494252, 0.9888021717000339]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzNRddvEPzDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save model\n",
        "model.save('model_binary.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuAvKKDBQfF2",
        "colab_type": "text"
      },
      "source": [
        "#Dynamic and Static classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6iEuSYxQpxS",
        "colab_type": "code",
        "outputId": "20733a3e-13d0-4941-bcb1-58af163bc696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'\n",
        "\n",
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]\n",
        "\n",
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = 'UCI_HAR_Dataset/'+subset+'/Inertial Signals/'+signal+'_'+subset+'.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))\n",
        "\n",
        "    \n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = 'UCI_HAR_Dataset/'+subset+'/y_'+subset+'.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return y #pd.get_dummies(y).as_matrix()\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0XLOzxqRKxL",
        "colab_type": "code",
        "outputId": "6a409b9e-4aa3-4554-beaf-e91169d6529c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9)\n",
            "(7352,)\n",
            "(2947, 128, 9)\n",
            "(2947,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftPLLb2esFKK",
        "colab_type": "code",
        "outputId": "18cbfa0b-8955-40c3-fd04-9aee2ecf782c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "a=Y_train.tolist()\n",
        "b=Y_train.argsort()\n",
        "b=b.tolist()\n",
        "print(a.count(1))\n",
        "print(a.count(2))\n",
        "print(a.count(3))\n",
        "print(a.count(4))\n",
        "print(a.count(5))\n",
        "print(a.count(6))\n",
        "\n",
        "print(\"------------------------\")\n",
        "\n",
        "dyn=a.count(1)+a.count(2)+a.count(3)\n",
        "print(dyn)\n",
        "sta=a.count(4)+a.count(5)+a.count(6)\n",
        "print(sta)\n",
        "\n",
        "print(\"------------------------\")\n",
        "\n",
        "b_dyn=b[0:3285]\n",
        "b_sta=b[3285:]\n",
        "print(len(b_dyn))\n",
        "print(len(b_sta))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1226\n",
            "1073\n",
            "986\n",
            "1286\n",
            "1374\n",
            "1407\n",
            "------------------------\n",
            "3285\n",
            "4067\n",
            "------------------------\n",
            "3285\n",
            "4067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpwS80__0bPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_dyn=[]\n",
        "X_train_sta=[]\n",
        "Y_train_dyn=[]\n",
        "Y_train_sta=[]\n",
        "\n",
        "for i in b_dyn :\n",
        "  m=X_train[i]\n",
        "  X_train_dyn.append(m)\n",
        "\n",
        "X_train_dyn=np.asarray(X_train_dyn)\n",
        "\n",
        "\n",
        "\n",
        "for i in b_sta :\n",
        "  n=X_train[i]\n",
        "  X_train_sta.append(n)\n",
        "\n",
        "X_train_sta=np.asarray(X_train_sta)\n",
        "\n",
        "\n",
        "for i in b_dyn :\n",
        "  p=Y_train[i]\n",
        "  Y_train_dyn.append(p)\n",
        "\n",
        "Y_train_dyn=np.asarray(Y_train_dyn)\n",
        "\n",
        "\n",
        "for i in b_sta :\n",
        "  q=Y_train[i]\n",
        "  Y_train_sta.append(q)\n",
        "\n",
        "Y_train_sta=np.asarray(Y_train_sta)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5g9ZXdDRhnG",
        "colab_type": "code",
        "outputId": "0a4d2a62-d786-4182-85a4-db519973c880",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "a=Y_test.tolist()\n",
        "b=Y_test.argsort()\n",
        "b=b.tolist()\n",
        "print(a.count(1))\n",
        "print(a.count(2))\n",
        "print(a.count(3))\n",
        "print(a.count(4))\n",
        "print(a.count(5))\n",
        "print(a.count(6))\n",
        "\n",
        "print(\"------------------------\")\n",
        "\n",
        "dyn=a.count(1)+a.count(2)+a.count(3)\n",
        "print(dyn)\n",
        "sta=a.count(4)+a.count(5)+a.count(6)\n",
        "print(sta)\n",
        "\n",
        "print(\"------------------------\")\n",
        "\n",
        "b_dyn=b[0:1387]\n",
        "b_sta=b[1387:]\n",
        "print(len(b_dyn))\n",
        "print(len(b_sta))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "496\n",
            "471\n",
            "420\n",
            "491\n",
            "532\n",
            "537\n",
            "------------------------\n",
            "1387\n",
            "1560\n",
            "------------------------\n",
            "1387\n",
            "1560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poy_Rv7zRjow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_dyn=[]\n",
        "X_test_sta=[]\n",
        "Y_test_dyn=[]\n",
        "Y_test_sta=[]\n",
        "\n",
        "for i in b_dyn :\n",
        "  m=X_test[i]\n",
        "  X_test_dyn.append(m)\n",
        "\n",
        "X_test_dyn=np.asarray(X_test_dyn)\n",
        "\n",
        "\n",
        "\n",
        "for i in b_sta :\n",
        "  n=X_test[i]\n",
        "  X_test_sta.append(n)\n",
        "\n",
        "X_test_sta=np.asarray(X_test_sta)\n",
        "\n",
        "\n",
        "for i in b_dyn :\n",
        "  p=Y_test[i]\n",
        "  Y_test_dyn.append(p)\n",
        "\n",
        "Y_test_dyn=np.asarray(Y_test_dyn)\n",
        "\n",
        "\n",
        "for i in b_sta :\n",
        "  q=Y_test[i]\n",
        "  Y_test_sta.append(q)\n",
        "\n",
        "Y_test_sta=np.asarray(Y_test_sta)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCdjFGA3RtV0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n, i in enumerate(Y_train_dyn):\n",
        "  if i == 1:\n",
        "    Y_train_dyn[n]=0\n",
        "  if i == 2:\n",
        "    Y_train_dyn[n]=1\n",
        "  if i == 3 :\n",
        "    Y_train_dyn[n]=2\n",
        "\n",
        "for n, i in enumerate(Y_test_dyn):\n",
        "  if i == 1:\n",
        "    Y_test_dyn[n]=0\n",
        "  if i == 2:\n",
        "    Y_test_dyn[n]=1\n",
        "  if i == 3 :\n",
        "    Y_test_dyn[n]=2\n",
        "\n",
        "\n",
        "for n, i in enumerate(Y_train_sta):\n",
        "  if i == 4:\n",
        "    Y_train_sta[n]=0\n",
        "  if i == 5:\n",
        "    Y_train_sta[n]=1\n",
        "  if i == 6 :\n",
        "    Y_train_sta[n]=2\n",
        "\n",
        "for n, i in enumerate(Y_test_sta):\n",
        "  if i == 4:\n",
        "    Y_test_sta[n]=0\n",
        "  if i == 5:\n",
        "    Y_test_sta[n]=1\n",
        "  if i == 6 :\n",
        "    Y_test_sta[n]=2\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "Y_train_dyn = np.array(Y_train_dyn)\n",
        "Y_test_dyn = np.array(Y_test_dyn )\n",
        "Y_train_sta = np.array(Y_train_sta)\n",
        "Y_test_sta = np.array(Y_test_sta)\n",
        "\n",
        "\n",
        "# one hot encode\n",
        "Y_train_dyn = to_categorical(Y_train_dyn)\n",
        "Y_test_dyn  = to_categorical(Y_test_dyn)\n",
        "Y_train_sta = to_categorical(Y_train_sta)\n",
        "Y_test_sta = to_categorical(Y_test_sta )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6p8HO1BZRvPz",
        "colab_type": "code",
        "outputId": "bab4dfe2-b105-4ff9-f31b-9bd5b6dcd4ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(X_train_dyn.shape)\n",
        "print(Y_train_dyn.shape)\n",
        "\n",
        "print(X_test_dyn.shape)\n",
        "print(Y_test_dyn.shape)\n",
        "\n",
        "print(X_train_sta.shape)\n",
        "print(Y_train_sta.shape)\n",
        "\n",
        "print(X_test_sta.shape)\n",
        "print(Y_test_sta.shape)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3285, 128, 9)\n",
            "(3285, 3)\n",
            "(1387, 128, 9)\n",
            "(1387, 3)\n",
            "(4067, 128, 9)\n",
            "(4067, 3)\n",
            "(1560, 128, 9)\n",
            "(1560, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5j3zFywglr6",
        "colab_type": "code",
        "outputId": "a63145c7-fcb2-47b3-a287-79d7f82995a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Dynamic class\n",
        "\n",
        "#Training with the best parameters\n",
        "\n",
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(64, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(3, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_dyn,\n",
        "          Y_train_dyn,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_test_dyn, Y_test_dyn),\n",
        "          epochs=20)\n",
        "\n",
        "# Confusion Matrix\n",
        "score = model.evaluate(X_test_dyn, Y_test_dyn)\n",
        "score"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 128, 64)           18944     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 31,459\n",
            "Trainable params: 31,459\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 3285 samples, validate on 1387 samples\n",
            "Epoch 1/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.9351 - acc: 0.5269 - val_loss: 0.8600 - val_acc: 0.6518\n",
            "Epoch 2/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.6118 - acc: 0.7820 - val_loss: 0.6088 - val_acc: 0.7938\n",
            "Epoch 3/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.3949 - acc: 0.8718 - val_loss: 0.5801 - val_acc: 0.8089\n",
            "Epoch 4/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.2778 - acc: 0.9215 - val_loss: 0.3091 - val_acc: 0.9113\n",
            "Epoch 5/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.1517 - acc: 0.9623 - val_loss: 0.2603 - val_acc: 0.9351\n",
            "Epoch 6/20\n",
            "3285/3285 [==============================] - 24s 7ms/step - loss: 0.1097 - acc: 0.9732 - val_loss: 0.2328 - val_acc: 0.9409\n",
            "Epoch 7/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0824 - acc: 0.9787 - val_loss: 0.1962 - val_acc: 0.9373\n",
            "Epoch 8/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0380 - acc: 0.9924 - val_loss: 0.1211 - val_acc: 0.9683\n",
            "Epoch 9/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0619 - acc: 0.9833 - val_loss: 0.1597 - val_acc: 0.9611\n",
            "Epoch 10/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0334 - acc: 0.9921 - val_loss: 0.1804 - val_acc: 0.9596\n",
            "Epoch 11/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0561 - acc: 0.9887 - val_loss: 0.1349 - val_acc: 0.9697\n",
            "Epoch 12/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0290 - acc: 0.9930 - val_loss: 0.2204 - val_acc: 0.9524\n",
            "Epoch 13/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0283 - acc: 0.9936 - val_loss: 0.0813 - val_acc: 0.9798\n",
            "Epoch 14/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0147 - acc: 0.9960 - val_loss: 0.1066 - val_acc: 0.9719\n",
            "Epoch 15/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0178 - acc: 0.9960 - val_loss: 0.2184 - val_acc: 0.9582\n",
            "Epoch 16/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0157 - acc: 0.9963 - val_loss: 0.2069 - val_acc: 0.9697\n",
            "Epoch 17/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0177 - acc: 0.9957 - val_loss: 0.2439 - val_acc: 0.9661\n",
            "Epoch 18/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0145 - acc: 0.9957 - val_loss: 0.0918 - val_acc: 0.9813\n",
            "Epoch 19/20\n",
            "3285/3285 [==============================] - 23s 7ms/step - loss: 0.0087 - acc: 0.9985 - val_loss: 0.1231 - val_acc: 0.9776\n",
            "Epoch 20/20\n",
            "3285/3285 [==============================] - 22s 7ms/step - loss: 0.0130 - acc: 0.9976 - val_loss: 0.2051 - val_acc: 0.9733\n",
            "1387/1387 [==============================] - 1s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.20508717492719, 0.9733237202595529]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVMLCYvLSRBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_dynamic.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1632a64a-4416-4e0b-ca54-2d9d0ea52cc6",
        "id": "_VFnzBnPA6o9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "#Training with the best parameters\n",
        "\n",
        "# Initiliazing the sequential model\n",
        "model = Sequential()\n",
        "# Configuring the parameters\n",
        "model.add(LSTM(64, input_shape=(timesteps, input_dim),return_sequences=True))\n",
        "# Adding a dropout layer\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(32))\n",
        "model.add(Dropout(0.5))\n",
        "# Adding a dense output layer with sigmoid activation\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adadelta',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "model.fit(X_train_sta,\n",
        "          Y_train_sta,\n",
        "          batch_size=32,\n",
        "          validation_data=(X_test_sta, Y_test_sta),\n",
        "          epochs=15)\n",
        "\n",
        "# Confusion Matrix\n",
        "score = model.evaluate(X_test_sta, Y_test_sta)\n",
        "score"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_4 (LSTM)                (None, 128, 64)           18944     \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 128, 64)           0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 31,459\n",
            "Trainable params: 31,459\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 4067 samples, validate on 1560 samples\n",
            "Epoch 1/15\n",
            "4067/4067 [==============================] - 29s 7ms/step - loss: 0.4482 - acc: 0.8153 - val_loss: 0.6911 - val_acc: 0.6744\n",
            "Epoch 2/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.3178 - acc: 0.8857 - val_loss: 0.4265 - val_acc: 0.8468\n",
            "Epoch 3/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.2507 - acc: 0.9127 - val_loss: 0.3549 - val_acc: 0.8654\n",
            "Epoch 4/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.2297 - acc: 0.9171 - val_loss: 0.3208 - val_acc: 0.8808\n",
            "Epoch 5/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.2243 - acc: 0.9179 - val_loss: 0.3064 - val_acc: 0.8942\n",
            "Epoch 6/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.2494 - acc: 0.9046 - val_loss: 0.3112 - val_acc: 0.8801\n",
            "Epoch 7/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.2137 - acc: 0.9171 - val_loss: 0.3788 - val_acc: 0.8660\n",
            "Epoch 8/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.2086 - acc: 0.9142 - val_loss: 0.3500 - val_acc: 0.8744\n",
            "Epoch 9/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.2747 - acc: 0.9105 - val_loss: 0.3229 - val_acc: 0.8744\n",
            "Epoch 10/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.2041 - acc: 0.9194 - val_loss: 0.3297 - val_acc: 0.8865\n",
            "Epoch 11/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.1998 - acc: 0.9189 - val_loss: 0.3180 - val_acc: 0.8814\n",
            "Epoch 12/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.1967 - acc: 0.9174 - val_loss: 0.3132 - val_acc: 0.8776\n",
            "Epoch 13/15\n",
            "4067/4067 [==============================] - 28s 7ms/step - loss: 0.1965 - acc: 0.9184 - val_loss: 0.3401 - val_acc: 0.8801\n",
            "Epoch 14/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.2130 - acc: 0.9164 - val_loss: 0.3520 - val_acc: 0.8776\n",
            "Epoch 15/15\n",
            "4067/4067 [==============================] - 27s 7ms/step - loss: 0.1990 - acc: 0.9225 - val_loss: 0.3538 - val_acc: 0.8827\n",
            "1560/1560 [==============================] - 2s 1ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.35382931890365005, 0.8826923076923077]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hL3r8WqVpWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('model_static.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tE2YypPpVw3g",
        "colab_type": "text"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCjCfUEeVwea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "import pickle\n",
        "model_binary = load_model('model_binary.h5')\n",
        "model_dynamic = load_model('model_dynamic.h5')\n",
        "model_static = load_model('model_static.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucBBLoBBWWnw",
        "colab_type": "code",
        "outputId": "5c6557ec-f159-426a-da84-7a0a63e01595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Data directory\n",
        "DATADIR = 'UCI_HAR_Dataset'\n",
        "\n",
        "# Raw data signals\n",
        "# Signals are from Accelerometer and Gyroscope\n",
        "# The signals are in x,y,z directions\n",
        "# Sensor signals are filtered to have only body acceleration\n",
        "# excluding the acceleration due to gravity\n",
        "# Triaxial acceleration from the accelerometer is total acceleration\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]\n",
        "\n",
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = 'UCI_HAR_Dataset/'+subset+'/Inertial Signals/'+signal+'_'+subset+'.txt'\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).as_matrix()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))\n",
        "\n",
        "    \n",
        "def load_y(subset):\n",
        "    \"\"\"\n",
        "    The objective that we are trying to predict is a integer, from 1 to 6,\n",
        "    that represents a human activity. We return a binary representation of \n",
        "    every sample objective as a 6 bits vector using One Hot Encoding\n",
        "    (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)\n",
        "    \"\"\"\n",
        "    filename = 'UCI_HAR_Dataset/'+subset+'/y_'+subset+'.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "    \n",
        "    return pd.get_dummies(y).as_matrix()\n",
        "\n",
        "\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, y_train, y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    y_train, y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Loading the train and test data\n",
        "X_train, X_test, Y_train, Y_test = load_data()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:51: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2o3dKETWbOA",
        "colab_type": "code",
        "outputId": "eedc10d3-9f97-464a-e5c5-bc9fb82002a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9)\n",
            "(7352, 6)\n",
            "(2947, 128, 9)\n",
            "(2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHPw8JlTWdzD",
        "colab_type": "code",
        "outputId": "9a5a4547-751e-4253-ec0d-f42f3615facc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#predict binary\n",
        "a=model_binary.predict_classes(X_test)\n",
        "b=np.argsort(a)\n",
        "a=a.tolist()\n",
        "print(a.count(0))\n",
        "print(a.count(1))\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1408\n",
            "1539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s7EzGSNfS9E",
        "colab_type": "code",
        "outputId": "19683851-e5ba-431e-95b5-5a1b78d7c354",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#separate dynamic and static classes\n",
        "dyn=b[0:1408]\n",
        "sta=b[1408:]\n",
        "\n",
        "print(dyn.shape)\n",
        "print(sta.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1408,)\n",
            "(1539,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJasNcJkWg6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_dyn=[]\n",
        "\n",
        "for i in dyn :\n",
        "    a=X_test[i]\n",
        "    x_test_dyn.append(a)\n",
        "x_test_dyn=np.asarray(x_test_dyn)\n",
        "\n",
        "x_test_sta=[]\n",
        "\n",
        "for i in sta :\n",
        "    a=X_test[i]\n",
        "    x_test_sta.append(a)\n",
        "x_test_sta=np.asarray(x_test_sta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHSWOjhrWqk4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dyn_pre=model_dynamic.predict_classes(x_test_dyn)\n",
        "sta_pre=model_static.predict_classes(x_test_sta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IxPkjh9WwPX",
        "colab_type": "code",
        "outputId": "28cf1b2e-ab0c-4853-f40e-cbf2533547db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "a=sta_pre\n",
        "a=a.tolist()\n",
        "print(a.count(0))\n",
        "print(a.count(1))\n",
        "print(a.count(2))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "406\n",
            "613\n",
            "520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDGFI77s37QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for n, i in enumerate(a):\n",
        "    if i == 0:\n",
        "        a[n] = 3\n",
        "    if i == 1:\n",
        "        a[n]=4\n",
        "    if i == 2 :\n",
        "        a[n]=5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuSy7zL4W0cd",
        "colab_type": "code",
        "outputId": "74b7aa34-f2f0-499d-8047-881add295fd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(a.count(3))\n",
        "print(a.count(4))\n",
        "print(a.count(5))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "406\n",
            "613\n",
            "520\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJVWmgLIW6HA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sta_pre=a\n",
        "sta_pre=np.asarray(sta_pre)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfsgdAyIW9a3",
        "colab_type": "code",
        "outputId": "15b8f287-3d80-4822-8072-6d5e16d04371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "print(type(dyn))\n",
        "print(type(sta))\n",
        "print(type(dyn_pre))\n",
        "print(type(sta_pre))\n",
        "\n",
        "print(dyn.shape)\n",
        "print(sta.shape)\n",
        "print(dyn_pre.shape)\n",
        "print(sta_pre.shape)\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(1408,)\n",
            "(1539,)\n",
            "(1408,)\n",
            "(1539,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McRtJpgXXDvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dyn_zip=list(zip(dyn, dyn_pre))\n",
        "sta_zip=list(zip(sta,sta_pre))\n",
        "\n",
        "d_s=dyn_zip+sta_zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orXfWX3SXG3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred=[]\n",
        "\n",
        "for i in range (0,2947):\n",
        "    y_pred.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFPD9QCSXI_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in d_s:\n",
        "    a=i[0]\n",
        "    b=i[1]\n",
        "    y_pred[a]=b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbnO-UA-XKd_",
        "colab_type": "code",
        "outputId": "c1aba3e7-50c3-4515-a803-197c4b893b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "y_pred = np.array(y_pred)\n",
        "print(y_pred)\n",
        "# one hot encode\n",
        "y_pred = to_categorical(y_pred)\n",
        "print(y_pred)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4 4 4 ... 1 1 1]\n",
            "[[0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " ...\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOfEIqbWXPkV",
        "colab_type": "code",
        "outputId": "22f8da4f-7077-44bf-887d-d8a3ecc113ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(Y_test, y_pred)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9141499830335935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}